{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "nA9Y7ga8ng1Z",
        "2VoM458Rq0lF",
        "I1K6VRn1GgtM",
        "9qNW_hnuHLzv",
        "KSlN3yHqYklG",
        "EM7whBJCYoAo",
        "4Of9eVA-YrdM",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "I_LbuSMXIInZ",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "GnJmLSdwIxW2",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "I9CodjG_I6S4",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "zNBCuBb2Jru9",
        "U2RJ9gkRphqQ",
        "RfCQldWiKI5B",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "Yfr_Vlr8HBkt",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AryamanChaudhary/Bike-Sharing-Demand-Prediction-/blob/main/ML_REGRESSION_PROJECT_DONE_BY_ARYAMAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n",
        "##### **Done By**         - Aryaman Chaudhary"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this project is to develop a predictive model that can accurately forecast demand for bike rentals in Seoul, South Korea, based on historical usage patterns, weather conditions, and other relevant factors. The project involves data collection, data preparation, feature engineering, model selection, hyperparameter tuning, model training, model evaluation, and model deployment.\n",
        "The project aims to help the bike-sharing program in Seoul optimize its resources, improve user satisfaction, and reduce operating costs. The project will leverage machine learning techniques and statistical analysis to build a robust and accurate predictive model that can help the bike-sharing program make data-driven decisions.\n",
        "The success of the project will be evaluated based on the model's ability to accurately predict bike rental demand, as well as its ability to provide valuable insights and recommendations for improving the bike-sharing program's operations. The project has the potential to not only benefit the bike-sharing program in Seoul but also serve as a model for other cities and organizations looking to optimize their resource allocation and improve their service offerings."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/AryamanChaudhary/Bike-Sharing-Demand-Prediction-/tree/main"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bike-sharing program in Seoul, South Korea, is experiencing low utilization rates and inefficient allocation of resources. The goal of this project is to develop a predictive model that can accurately forecast demand for bike rentals based on historical usage patterns, weather conditions, and other relevant factors. By doing so, we aim to help the bike-sharing program optimize its resources, improve user satisfaction, and reduce operating costs."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import datetime as dt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount = ('/content/SeoulBikeData.csv')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/SeoulBikeData.csv' , encoding = 'latin')"
      ],
      "metadata": {
        "id": "AZ8BXI_TH2fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "data"
      ],
      "metadata": {
        "id": "hADlKoKkKln4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Viewing  top five rows in the given dataset by using head()\n",
        "data.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Viewing the last five rows of the dataset bt using tail()\n",
        "data.tail()"
      ],
      "metadata": {
        "id": "MltarmeSKPUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting the rows and columns in the dataset\n",
        "print(f'Number of rows : {len(data.axes[0])}')\n",
        "print(f'Number of columns : {len(data.axes[1])}')"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can also use shape to get the numbers of the rows and columns\n",
        "data.shape"
      ],
      "metadata": {
        "id": "soZqNcnxLFjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "# Viewing the info of the given dataset by using info()\n",
        "data.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "# Checking if are there any duplicate values or not\n",
        "print(f' Total number of duplicate values  : {data.duplicated().sum()}')"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(data.isnull(), cbar=False);"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* There are 8760 observation and 14 features.\n",
        "\n",
        "* In a day we have 24 hours and we have 365 days a year so 365 multiplied by 24 = 8760, which represents the number of line in the dataset\n",
        "\n",
        "* There are no null values.\n",
        "* Dataset has all unique values i.e., there is no duplicate, which means data is free from bias as duplicates which can cause problems in downstream analysis.\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "print(f' Columns : {data.columns}')"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "data.describe()\n"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Date : The date of the day, during 365 days from 01/12/2017 to 30/11/2018, formating in DD/MM/YYYY, type : str, we need to convert into datetime format.\n",
        "\n",
        "* Rented Bike Count : Number of rented bikes per hour which our dependent variable and we need to predict that, type : int\n",
        "\n",
        "* Hour: The hour of the day, starting from 0-23 it's in a digital time format, type : int, we need to convert it into category data type.\n",
        "\n",
        "* Temperature(°C): Temperature in Celsius, type : Float\n",
        "\n",
        "* Humidity(%): Humidity in the air in %, type : int\n",
        "\n",
        "* Wind speed (m/s) : Speed of the wind in m/s, type : Float\n",
        "\n",
        "* Visibility (10m): Visibility in m, type : int\n",
        "\n",
        "* Dew point temperature(°C): Temperature at the beggining of the day, type : Float\n",
        "\n",
        "* Solar Radiation (MJ/m2): Sun contribution, type : Float\n",
        "\n",
        "* Rainfall(mm): Amount of raining in mm, type : Float\n",
        "\n",
        "* Snowfall (cm): Amount of snowing in cm, type : Float\n",
        "\n",
        "* Seasons: Season of the year, type : str, there are only 4 season's in data .\n",
        "\n",
        "* Holiday: If the day is holiday period or not, type: str\n",
        "\n",
        "* Functioning Day: If the day is a Functioning Day or not, type : str"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Using for loop to check the unique values.\n",
        "for dataset in data.columns:\n",
        "  print(f\"No. of unique values in {dataset} is {data[dataset].nunique()}.\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PROCESSING THE DATA"
      ],
      "metadata": {
        "id": "y-NruRwZrFFg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BREAKING DATE COLUMN"
      ],
      "metadata": {
        "id": "2VoM458Rq0lF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['Date'] = data['Date'].str.replace('-', '/')\n",
        "data['Date'] = data['Date'].apply(lambda x: dt.datetime.strptime(x, \"%d/%m/%Y\"))\n"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can see that the Date variable is in object datatype, we need to change it into datetime datatype\n",
        "data['Date'] = data['Date'].astype(np.datetime64)\n",
        "\n",
        "data['month'] = data['Date'].dt.month\n",
        "\n",
        "data['day'] = data['Date'].dt.day_name()\n",
        "\n"
      ],
      "metadata": {
        "id": "vafdWQlHihE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping Date variable from dataset\n",
        "data.drop(['Date'],axis = 1, inplace = True)\n"
      ],
      "metadata": {
        "id": "4YaYa77HpXGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining separate data as numerical and categorical data.\n",
        "\n",
        "# Numerical data\n",
        "\n",
        "numerical_data = list(set(data.describe().columns.tolist()) - {'Hour','month'})\n",
        "\n",
        "# Categorical data\n",
        "\n",
        "categorical_data = list(set(data.columns)-set(numerical_data))"
      ],
      "metadata": {
        "id": "l4FJ69Qdpo43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#let's check the result of data type\n",
        "data.info()"
      ],
      "metadata": {
        "id": "KduRT1DPqTFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here are the final columns\n",
        "data.columns"
      ],
      "metadata": {
        "id": "Yp3Ife9TqZ77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Changed Date column datatype from object to Datetime data type.\n",
        "\n",
        "* Created new columns Day and Month from date column and dropped Date.\n",
        "\n",
        "* Defining separate data as numerical and categorical data."
      ],
      "metadata": {
        "id": "acXB_5E5pqw6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EDA OF THE DATASET"
      ],
      "metadata": {
        "id": "EcHX0JM6wht_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis of Dependent Variable:\n",
        "### What is a dependent variable in data analysis?\n",
        "\n",
        "* we analyse our dependent variable,A dependent variable is a variable whose value will change depending on the value of another variable.*"
      ],
      "metadata": {
        "id": "_DFqcBqjw0ky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Analysation of categorical variables\n",
        "* Our dependent variable is \"Rented Bike Count\" so we need to analysis this column with the other columns by using some visualisation plot.first we analyze the category data type then we proceed with the numerical data type*"
      ],
      "metadata": {
        "id": "TlMokOXkxL5F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visualizing data distribution of our dependent variable (Rented Bike Count)"
      ],
      "metadata": {
        "id": "I1K6VRn1GgtM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.title('Rented Bike Count')\n",
        "sns.distplot(data['Rented Bike Count'] )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tWAE-i-FGfQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Why did you pick the specific chart?\n",
        "Distplot is one of the best charts to show the data distribution.\n",
        "\n",
        "##2. What is/are the insight(s) found from the chart?\n",
        "Data is positively skewed may need to transform it further.\n",
        "\n",
        "##3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "As of now we know that the data is positively skewed that means the bike demand for smaller bulks is more."
      ],
      "metadata": {
        "id": "m9bZtfFWGvM8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualizing data distribution of categorical data with respect to Rented Bike Count."
      ],
      "metadata": {
        "id": "9qNW_hnuHLzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart 2\n",
        "\n",
        "# Creating a for loop for visualizing all the categorical data with respect to Rented Bike Count.\n",
        "\n",
        "for i in categorical_data:\n",
        "    plt.figure(figsize=(15,6))\n",
        "    plt.title(i)\n",
        "    sns.barplot(x = data[i], y = data['Rented Bike Count'])\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Why did you pick the specific chart?\n",
        "* To visualise and spread categorical data with respect to Rented Bike Count."
      ],
      "metadata": {
        "id": "iQfdZNMAyrTI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. What is/are the insight(s) found from the chart?\n",
        "The peak hours of rented bikes is 5:00PM - 7:00PM and the least bikes are rented between 3:00AM to 5:00AM.\n",
        "\n",
        "* June is the peak and January is the bottom months for number of rented bikes.\n",
        "\n",
        "* Highest no. of bikes are booked on Thursday and the least on Sunday.\n",
        "\n",
        "* People prefer renting bikes most in the Summer season and the least in winter season.\n",
        "\n",
        "* People rented more bikes on a non-holiday compared to a holiday."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "* The above gained insights can definitely help creating a positive business impact, we got to know how time, month, day, season and holiday impact the number of rented bikes, we can make strategies accordingly."
      ],
      "metadata": {
        "id": "EP4_9CUYEupn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Bike Rent Count trend with respect to Hours on Months"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Chart - 3 visualization code\n",
        "\n",
        "# Using pointplot for multivariate analysis.\n",
        "\n",
        "plt.figure(figsize = (18,6))\n",
        "sns.pointplot(x = data['Hour'], y = data['Rented Bike Count'], hue = data['month'])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Why did you pick the specific chart?\n",
        "* To do a multivariate analysis among Hour, Rented Bike Count and Months\n",
        "\n",
        "## 2. What is/are the insight(s) found from the chart?\n",
        "* June is the peak and January is the bottom months for number of rented bikes.\n",
        "\n",
        "\n",
        "## 3. Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "* The above gained insights can definitely help creating a positive business impact, we got to know how month impact the number of rented bikes, we can make strategies accordingly."
      ],
      "metadata": {
        "id": "gumcq0DuFDak"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bike Rent Count trend with respect Hours on Seasons."
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Chart - 4 visualization code\n",
        "\n",
        "# Using pointplot for multivariate analysis.\n",
        "\n",
        "plt.figure(figsize = (18,8))\n",
        "sns.pointplot(x = data['Hour'], y = data['Rented Bike Count'], hue = data['Seasons'])\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Why did you pick the specific chart?\n",
        "To do a multivariate analysis among Hour, Rented Bike Count and Months\n",
        "\n",
        "##2. What is/are the insight(s) found from the chart?\n",
        "People prefer renting bikes most in the Summer season and the least in winter season.\n",
        "\n",
        "##3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "The above gained insights can definitely help creating a positive business impact, we got to know how Seasons impact the number of rented bikes, we can make strategies accordingly."
      ],
      "metadata": {
        "id": "L2kpRBZ2HdUN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bike Rent Count trend with respect Hours on Days."
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "\n",
        "# Using pointplot for multivariate analysis.\n",
        "\n",
        "plt.figure(figsize = (18,8))\n",
        "sns.pointplot(x = data['Hour'], y = data['Rented Bike Count'], hue = data['day'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To do a multivariate analysis among Hour, Rented Bike Count and Day."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Highest no. of bikes are booked on Thursday and the least on Sunday."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above gained insights can definitely help creating a positive business impact, we got to know how Days impact the number of rented bikes, we can make strategies accordingly."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Bike Rent Count trend with respect Hours on Holidays."
      ],
      "metadata": {
        "id": "I_LbuSMXIInZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "\n",
        "# Using pointplot for multivariate analysis.\n",
        "\n",
        "plt.figure(figsize = (18,8))\n",
        "sns.pointplot(x = data['Hour'], y = data['Rented Bike Count'], hue = data['Holiday'])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To do a multivariate analysis among Hour, Rented Bike Count and Holiday."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "People rented more bikes on a non-holiday compared to a holiday."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above gained insights can definitely help creating a positive business impact, we got to know how Holidays impact the number of rented bikes, we can make strategies accordingly."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualizing outliers using box plot of numeric columns."
      ],
      "metadata": {
        "id": "GnJmLSdwIxW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "\n",
        "# Writing code for creating a for loop for numerical variables and creting box plots.\n",
        "\n",
        "for i in numerical_data:\n",
        "  plt.figure(figsize = (18,6))\n",
        "  sns.boxplot(x = data[i])\n",
        "  plt.title(i)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Boxplots as we need to identify outliers."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rainfall, Solar Radiation, Snowfall and Windspeed has high numbers of outliers."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In some cases, outliers may represent opportunities for business growth. For example, if there are a small number of customers who are making a significantly higher number of bike rentals than the average customer, this may represent a market segment that can be targeted for special promotions or marketing campaigns."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lets check the linear relationship between the dependent variable-\"Rented Bike Count' and remaining columns(independent variables)."
      ],
      "metadata": {
        "id": "I9CodjG_I6S4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code using regplot.\n",
        "for i in numerical_data:\n",
        "  if i not in ['Rented Bike Count']:\n",
        "    fig = plt.figure(figsize = (18,7))\n",
        "    fig = plt.gca()\n",
        "\n",
        "    sns.regplot(\n",
        "        data=data, x=i, y=\"Rented Bike Count\",\n",
        "        truncate=False, order=2, color=\".2\",scatter_kws={'color':'green'}\n",
        "    )\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used regplot as it allows us to quickly visualize the relationship between two variables and determine whether there is a linear or non-linear relationship between them."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hour:\n",
        "* There is sudden peak between 6/7AM to 10 AM. Office time,College and going time could be the reason for this sudden peak.\n",
        "\n",
        "* Again there is peak between 10 AM to 7 PM. may be its office leaving time for the above people.\n",
        "\n",
        "* We can say that,from morning 7 AM to Evening 7 PM we have good Bike Rent Count. and from 7 PM to 7 AM Bike Rent count starts declining.\n",
        "\n",
        "\n",
        "##Rainfall And snowfall:\n",
        "* Its very obivious that people usually do not like ride bikes in rain and snowfall.\n",
        "\n"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above gained insights can definitely help creating a positive business impact, we got to know how the variables impact the number of rented bikes, we can make strategies accordingly."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualizing the data distribution on the dependent variable before normalization."
      ],
      "metadata": {
        "id": "zNBCuBb2Jru9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "# Visualizing the data distribution on the dependent variable using distplot and boxplot charts.\n",
        "\n",
        "f, axes = plt.subplots(1, 2,figsize=(18,7))\n",
        "sns.distplot(x=(data['Rented Bike Count']),color='r',ax=axes[0])\n",
        "sns.boxplot(x=(data['Rented Bike Count']),color='r',ax=axes[1])\n",
        "plt.title(\"Outliers on 'Rented Bike Count' variable before normalization.\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualizing the data distribution on the dependent variable after normalization."
      ],
      "metadata": {
        "id": "RfCQldWiKI5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "# Normalizing  our target variable by squre root method\n",
        "\n",
        "f, axes = plt.subplots(1, 2,figsize=(18,8))\n",
        "sns.distplot(x=np.sqrt(data['Rented Bike Count']),color='g',ax=axes[0])\n",
        "sns.boxplot(x=np.sqrt(data['Rented Bike Count']),color='g',ax=axes[1])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used distplot to visualize the distribution of data and using boxplot to detect outliers."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* As we can see from both the charts the distribution of the data is less skewed and is moving towards normally distributed data\n",
        "\n",
        "* The outliers are also gone after normalization."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Improved accuracy, comparability and better visualization are the result of normalization which can improve model performance."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualizing data distribution of numerical data."
      ],
      "metadata": {
        "id": "FtICkh_mKlQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "# Creating a for loop for visualizing all the numerical variables using distplot.\n",
        "\n",
        "for i in numerical_data:\n",
        "  if i not in ['Rented Bike Count']:\n",
        "    plt.figure(figsize=(15,6))\n",
        "    plt.title(i)\n",
        "    sns.distplot(data[i] )\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distplot is one of the best charts to show the data distribution.And most of the people understand it easily."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Solar radiation, Snowfall, Rainfall and visibility are highly skewed."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that weather influences the output in a big way as the data for Solar radiation, Snowfall, Rainfall and visibility are highly skewed we can say that people choose riding a bike on specific weather conditions."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Checking Corelation between dependent and independent variable using Correlation Heatmap visualization."
      ],
      "metadata": {
        "id": "cZ_SQWTnL7x2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "corr = data.corr()\n",
        "\n",
        "plt.figure(figsize = (18,8))\n",
        "sns.heatmap(corr, annot = True , cmap = 'coolwarm')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used correlation heatmap to visualize the correlation among variables."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temperature and Dew point Temperature are highly correlated. As per our regression assumption, there should not be colinearity between independent variables. We can see from the heatmap that \"Temperature\" and \"Dew Point Temperature\" are highly corelated. We can drop one of them.As the corelation between temperature and our dependent variable \"Bike Rented Count\" is high. So we will Keep the Temperature column and drop the \"Dew Point Temperature\" column."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "sns.pairplot(data = data)"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* null_hypothesis = 'There is no relationship between temperature and bike demand in Seoul.'\n",
        "\n",
        "* alt_hypothesis = 'There is a relationship between temperature and bike demand in Seoul.'"
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "import statsmodels.api as sm\n",
        "\n",
        "\n",
        "# Define null and alternative hypotheses\n",
        "null_hypothesis = 'There is no relationship between temperature and Rented Bike Count.'\n",
        "alt_hypothesis = 'There is a relationship between temperature and Rented Bike Count.'\n",
        "\n",
        "# Perform linear regression\n",
        "X = sm.add_constant(data['Temperature(°C)'])\n",
        "y = data['Rented Bike Count']\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Print summary statistics\n",
        "print(model.summary())\n",
        "\n",
        "# Extract p-value for temperature coefficient\n",
        "p_value = model.pvalues[1]\n",
        "print('p-value:', p_value)"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* We use the OLS (ordinary least squares) function from the statsmodels package to perform a linear regression of bike demand on temperature.\n",
        "\n",
        "* The p-value associated with the temperature coefficient is shown under the column \"P>|t|\", and is equal to 0.000 in this example. Since this p-value is less than the significance level of 0.05, we can reject the null hypothesis and conclude that there is evidence of a significant relationship between temperature and bike demand in Seoul."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* I chose linear regression as the statistical test to perform hypothesis testing for Seoul bike sharing demand prediction because it is a commonly used method for analyzing the relationship between a continuous predictor variable and a continuous response variable. In this case, we are interested in determining whether there is a significant relationship between a predictor variable, such as temperature or time of day, and bike demand."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* null_hypothesis = 'There is no relationship between month and bike demand in Seoul.'\n",
        "\n",
        "* alt_hypothesis = 'There is a relationship between month and bike demand in Seoul.'"
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "null_hypothesis = 'There is no relationship between month and Rented Bike Count.'\n",
        "alt_hypothesis = 'There is a relationship between month and Rented Bike Count.'\n",
        "\n",
        "# Perform linear regression\n",
        "X = sm.add_constant(data['month'])\n",
        "y = data['Rented Bike Count']\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Print summary statistics\n",
        "print(model.summary())\n",
        "\n",
        "# Extract p-value for temperature coefficient\n",
        "p_value = model.pvalues[1]\n",
        "print('p-value:', p_value)"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the OLS (ordinary least squares) function from the statsmodels package to perform a linear regression of bike demand on month.\n",
        "\n",
        "The p-value associated with the month coefficient is shown under the column \"P>|t|\", and is equal to 3.144647620349008e-11 in this example. Since this p-value is less than the significance level of 0.05, we can reject the null hypothesis and conclude that there is evidence of a significant relationship between month and bike demand in Seoul."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose linear regression as the statistical test to perform hypothesis testing for Seoul bike sharing demand prediction because it is a commonly used method for analyzing the relationship between a continuous predictor variable and a continuous response variable. In this case, we are interested in determining whether there is a significant relationship between a predictor variable, such as temperature or time of day, and bike demand."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* null_hypothesis = 'There is no relationship between Hour and Bike demand in Seoul.'\n",
        "* alt_hypothesis = 'There is a relationship between Hour and Bike demand in Seoul.'"
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "null_hypothesis = 'There is no relationship between Hour and bike Rented Bike Count.'\n",
        "alt_hypothesis = 'There is a relationship between Hour and bike Rented Bike Count.'\n",
        "\n",
        "# Perform linear regression\n",
        "X = sm.add_constant(data['Hour'])\n",
        "y = data['Rented Bike Count']\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Print summary statistics\n",
        "print(model.summary())\n",
        "\n",
        "# Extract p-value for temperature coefficient\n",
        "p_value = model.pvalues[1]\n",
        "print('p-value:', p_value)"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the OLS (ordinary least squares) function from the statsmodels package to perform a linear regression of bike demand on Hour.\n",
        "\n",
        "The p-value associated with the Hour coefficient is shown under the column \"P>|t|\", and is equal to 0.0 in this example. Since this p-value is less than the significance level of 0.05, we can reject the null hypothesis and conclude that there is evidence of a significant relationship between Hour and Rented Bike Count."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose linear regression as the statistical test to perform hypothesis testing for Seoul bike sharing demand prediction because it is a commonly used method for analyzing the relationship between a continuous predictor variable and a continuous response variable. In this case, we are interested in determining whether there is a significant relationship between a predictor variable, such as temperature or time of day, and bike demand."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "# Checking if there is any null value in the dataset.\n",
        "\n",
        "data.isnull().sum()\n"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* No missing/null values in the dataset."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding the categorical columns:\n",
        "\n",
        "# First encoding Holiday as '1' and '0' replacing 'Holiday' and 'No-Holiday':\n",
        "\n",
        "data['Holiday'] = data['Holiday'].apply(lambda x: 1 if x == 'Holiday' else 0)\n",
        "\n",
        "\n",
        "# Encoding 'Functioning Day' as '1' and '0' replacing 'Yes' and 'No':\n",
        "\n",
        "data['Functioning Day'] = data['Functioning Day'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "\n",
        "\n",
        "# Creating new feature 'weekend' from 'Day' as '1' and '0' replacing ['Sunday','Saturday'] and weekdays:\n",
        "\n",
        "data['weekend'] = data['day'].apply(lambda x: 1 if x in ['Sunday','Saturday'] else 0 )\n",
        "\n",
        "\n",
        "# Using one hot encoding on 'Seasons' and 'Hours' features to create dummy variables:\n",
        "\n",
        "data = pd.get_dummies(data, columns = ['Seasons','Hour'])\n"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "features = list(set(data.describe().columns) - set(['Dew point temperature(°C)','Humidity(%)','Visibility (10m)']))\n",
        "features"
      ],
      "metadata": {
        "id": "qy1vEwvKHxWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used manual categorical encoding and One hot encoding which is a technique used in data preprocessing and feature engineering to represent categorical variables as numerical features that can be used as inputs to machine learning models."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "# Defining a function for getting the variance inflation factor.\n",
        "\n",
        "def Calculate_vif(X):\n",
        "\n",
        "    # Calculating VIF\n",
        "    vif = pd.DataFrame()\n",
        "    vif[\"variables\"] = X.columns\n",
        "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "    return(vif)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating VIF for variables.\n",
        "\n",
        "Calculate_vif(data[[i for i in data.describe().columns if i not in ['Rented Bike Count']]])\n",
        "\n",
        "# Not including 'Rented Bike Count' is the dependent variable."
      ],
      "metadata": {
        "id": "IAMIYj2-7uQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Calculate_vif(data[[i for i in data.describe().columns if i not in ['Rented Bike Count','Dew point temperature(°C)']]])\n"
      ],
      "metadata": {
        "id": "mwPX870s7vRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Calculate_vif(data[[i for i in data.describe().columns if i not in ['Rented_Bike_Count','Dew point temperature(°C)','Humidity(%)']]])\n"
      ],
      "metadata": {
        "id": "7VVLZgQD7vqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Not including 'Visibility (10m)' as it has high VIF.\n",
        "\n",
        "Calculate_vif(data[[i for i in data.describe().columns if i not in ['Rented_Bike_Count','Dew point temperature(°C)','Humidity(%)','Visibility (10m)']]])\n"
      ],
      "metadata": {
        "id": "tkhWDhm8J3ZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now we have VIF values in the range of 1 to 5. we will drop 'Humidity', 'Dew point temperature(°C)', 'Visibility' because these columns from our dataset shown colinearity in VIF test."
      ],
      "metadata": {
        "id": "V4C3-nQjK-5Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "# Selecting the features which are not colinear among themselves and whose VIF is less than 5.\n",
        "\n",
        "features = list(set(data.describe().columns) - set(['Rented_Bike_Count','Dew point temperature(°C)','Humidity(%)','Visibility (10m)']))\n",
        "features"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used VIF(Variance Inflation Factor). It is a measure of multicollinearity in regression analysis that quantifies how much the variance of the estimated regression coefficients are increased due to the linear dependence between the predictor variables.\n",
        "\n",
        "And along with that we did manual feature elimination using VIF."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have selected these features as they show least amount of multicolinearity -\n",
        "\n",
        "['Snowfall (cm)', 'Wind speed (m/s)', 'Solar Radiation (MJ/m2)', 'Rented Bike Count', 'Temperature(°C)', 'Hour', 'Rainfall(mm)', 'month']"
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "\n",
        "# Splitting the data to train and test.\n",
        "\n",
        "X = data[list(set(features)- {'Rented Bike Count'})]\n",
        "\n",
        "# Using Square root on dependent variable to normalize the variable.\n",
        "\n",
        "Y = np.sqrt(data['Rented Bike Count'])\n",
        "\n",
        "# Splitting data, 70% for training and 30% for testing using train_test_split.\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size = 0.30, random_state= 0)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used 70-30 ratio to split train and test data.Because it is convienient."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "# Using StandardScaler() standardization technique to scale data:\n",
        "\n",
        "scaler  = StandardScaler()\n",
        "\n",
        "# Fitting x_train and x_test using StandardScaler():\n",
        "\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Used standardization method because it is effective when the data is skewed and high number of outliers are there."
      ],
      "metadata": {
        "id": "Xi0tCaEuLUJg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining function to calculate different model accuracy scores.\n",
        "\n",
        "def calc_scores(true, pred):\n",
        "  MAE= mean_absolute_error(true, pred)\n",
        "  print(f\"The Mean Absolute Error (MAE) is {MAE}.\")\n",
        "\n",
        "  #Calculate  Mean Squared Error\n",
        "  MSE=mean_squared_error(true, pred)\n",
        "  print(f\"The Mean Squred Error(MSE) is {MSE}.\")\n",
        "\n",
        "  #Calculate Root Mean Squared Error\n",
        "  RMSE=np.sqrt(MSE)\n",
        "  print(f\"The Root Mean Squared Error(RMSE) is {RMSE}.\")\n",
        "\n",
        "  #Calculate R2 Score\n",
        "  R2=r2_score(true, pred)\n",
        "  print(f\"The R2 Score is {R2}.\")\n"
      ],
      "metadata": {
        "id": "G8MoiD52M4aD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a function which appends all the model scores in a dataframe modelwise:\n",
        "\n",
        "# Making an empty dataframe:\n",
        "\n",
        "score_df = pd.DataFrame({'Model':[],'Mean Absolute Error (MAE)':[], 'Mean Squred Error(MSE)':[], 'The Root Mean Squared Error(RMSE)':[], 'R2 Score':[]})\n",
        "\n",
        "# Code for the store_score function:\n",
        "\n",
        "def store_scores(Model, MAE, MSE, RMSE, R2):\n",
        "  scores = {'Model':Model,'Mean Absolute Error (MAE)':MAE, 'Mean Squred Error(MSE)':MSE, 'The Root Mean Squared Error(RMSE)':RMSE, 'R2 Score':R2}\n",
        "  global score_df\n",
        "  score_df = score_df.append(scores, ignore_index=True)\n",
        "  return score_df\n"
      ],
      "metadata": {
        "id": "oHhNC59wM4J1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining function which visualize linearity of real and predicted data:\n",
        "\n",
        "def reg_scatter(true, pred):\n",
        "  plt.figure(figsize=(10,8))\n",
        "\n",
        "  sns.regplot(x= true, y = pred, scatter_kws={'color':'magenta'},line_kws={'color':'black'})\n",
        "\n",
        "  plt.legend([\"Actual\",\"Predicted\",])\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "58I1BZm_M2cP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining a function for visualizing feature importance bar graph:\n",
        "\n",
        "def feature_imp(model):\n",
        "  model1 = [model]\n",
        "\n",
        "  best_rf = model.predict\n",
        "\n",
        "  feature_importances = best_rf.feature_importances_\n",
        "\n",
        "  # Create a dataframe of feature importances with their corresponding feature names\n",
        "  feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
        "\n",
        "  # Sort the features by importance in descending order\n",
        "  feature_importance_df = feature_importance_df.sort_values('Importance', ascending=False)\n",
        "\n",
        "  # Plot the feature importances in a horizontal bar plot\n",
        "  sns.set_style(\"whitegrid\")\n",
        "  plt.figure(figsize=(15,8))\n",
        "  sns.barplot(x='Importance', y='Feature', data=feature_importance_df, color='blue', order=feature_importance_df['Feature'])\n",
        "  if model1 == [model]:\n",
        "    plt.title(\"Feature Importances for Random Forest Regression Model with Grid Search CV\")\n",
        "  else:\n",
        "    plt.title(\"Feature Importances for Gradiend Boosting Regression Model with Grid Search CV\")\n",
        "  plt.xlabel(\"Importance\")\n",
        "  plt.ylabel(\"Feature\")\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "ncbW2wRfM-Or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Linear Regression\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "27iPK01eNKTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "lin_reg = LinearRegression()\n",
        "\n",
        "# Fit the Algorithm\n",
        "reg = lin_reg.fit(x_train, y_train)\n",
        "\n",
        "# Predict on the model\n",
        "y_train_pred = reg.predict(x_train)\n",
        "y_test_pred = reg.predict(x_test)\n",
        "\n",
        "# Finding the coefficients and intercept from the model-\n",
        "\n",
        "print(f'The coefficients of the model is {reg.coef_}')\n",
        "print(f'The intercept of the model is {reg.intercept_}')"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Checking model train and test score:\n",
        "\n",
        "\n",
        "print(f'Linear Regression model train score is :{reg.score(x_train, y_train)}')\n",
        "\n",
        "print(f'Linear Regression model test score is :{reg.score(x_test, y_test)}')"
      ],
      "metadata": {
        "id": "PnEL7oD3Ogru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating model performance scores for train data.\n",
        "\n",
        "calc_scores(y_train, y_train_pred)"
      ],
      "metadata": {
        "id": "jzoSX036OgeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating model performance scores for test data.\n",
        "\n",
        "calc_scores(y_test, y_test_pred)"
      ],
      "metadata": {
        "id": "8BN9ibDWOji-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualizing linearity between real and predicted data:\n",
        "\n",
        "reg_scatter(y_test, y_test_pred)"
      ],
      "metadata": {
        "id": "MxeHMPqiSn3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "store_scores('Linear regression',5.025080868159481, 43.41177115815907, 6.588760972911301, 0.7173677593343155)"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##The model used is Linear Regression and the performance of the model was evaluated using various evaluation metrics such as mean squared error (MSE), mean absolute error (MAE), and R-squared value. These metrics were calculated on both the training and testing sets to determine the overall performance of the model.\n",
        "##The linear regression model achieved a mean squared error of 43.41177115815907 and a mean absolute error of 5.025080868159481 on the testing set. The R-squared value was 0.7173677593343155, indicating that the model explained 71.73% of the variance in the data."
      ],
      "metadata": {
        "id": "KKPWNwBRPrDV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Lasso Regression\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "jvG8TsKZTRtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation\n",
        "\n",
        "lasso = Lasso()\n",
        "\n",
        "\n",
        "# Fitting the Algorithm\n",
        "lasso.fit(x_train, y_train)\n",
        "\n",
        "\n",
        "# Predicting on the model\n",
        "y_pred_trlasso = lasso.predict(x_train)\n",
        "y_pred_telasso = lasso.predict(x_test)\n",
        "\n",
        "# Finding the coefficients and intercept from the model-\n",
        "\n",
        "print(f'The coefficients of the model is {np.array(lasso.coef_)}')\n",
        "print(f'The intercept of the model is {lasso.intercept_}')\n"
      ],
      "metadata": {
        "id": "YFOEfYIXTX1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking model train and test score:\n",
        "\n",
        "\n",
        "print(f'Lasso Regression model train score is :{lasso.score(x_train, y_train)}\\n')\n",
        "\n",
        "print(f'Lasso Regression model test score is :{lasso.score(x_test, y_test)}')"
      ],
      "metadata": {
        "id": "lFW39KcITXvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating model performance scores for train data.\n",
        "\n",
        "calc_scores(y_train, y_pred_trlasso)"
      ],
      "metadata": {
        "id": "dkQBy0P0TXpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating model performance scores for test data.\n",
        "\n",
        "calc_scores(y_test, y_pred_telasso)\n"
      ],
      "metadata": {
        "id": "uhkZgHoBTXh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualizing linearity between real and predicted data:\n",
        "\n",
        "reg_scatter(y_test, y_pred_telasso)"
      ],
      "metadata": {
        "id": "LBhp-CNlTXVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "store_scores('Lasso regression',6.084010902487589, 61.1274611692987, 7.818405283003606, 0.6020297984723794)"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementation with hyperparameter optimization techniques using GridSearch CV:\n",
        "# Create the model\n",
        "model = Lasso()\n",
        "\n",
        "# Define the hyperparameters to tune\n",
        "params = {'alpha': [1e-15, 1e-13, 1e-10, 1e-08, 1e-05, 0.0001,\n",
        "                                   0.001, 0.01, 0.1, 1, 5, 10, 20, 30, 40, 45,\n",
        "                                   50, 55, 60, 100],}\n",
        "\n",
        "# Create the grid search object\n",
        "grid = GridSearchCV(model, params, cv=5)\n",
        "\n",
        "# Fit the model\n",
        "grid.fit(x_train, y_train)\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best hyperparameters: {}\".format(grid.best_params_))\n",
        "print(\"Best mean cross-validation score: {:.2f}\".format(grid.best_score_))"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the model using tuned hyperparameter\n",
        "\n",
        "lasso = Lasso(alpha =  0.01)\n",
        "\n",
        "# Fitting the Algorithm\n",
        "lasso.fit(x_train, y_train)\n",
        "\n",
        "\n",
        "# Predicting on the model\n",
        "y_pred_trlasso = lasso.predict(x_train)\n",
        "y_pred_telasso = lasso.predict(x_test)\n",
        "\n",
        "# Finding the coefficients and intercept from the model-\n",
        "\n",
        "print(f'The coefficients of the model is {np.array(lasso.coef_)}')\n",
        "print(f'The intercept of the model is {lasso.intercept_}')\n"
      ],
      "metadata": {
        "id": "E2ocsdX7T6qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating model performance scores for train data.\n",
        "\n",
        "calc_scores(y_train, y_pred_trlasso)"
      ],
      "metadata": {
        "id": "Q71XpBTYT6ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating model performance scores for test data.\n",
        "\n",
        "calc_scores(y_test, y_pred_telasso)"
      ],
      "metadata": {
        "id": "nV5QFlqbT6Yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualizing linearity between real and predicted data:\n",
        "\n",
        "reg_scatter(y_test, y_pred_telasso)\n"
      ],
      "metadata": {
        "id": "jv-OGSkQT6Rn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Here I used Grid search cross validation hyperparameter optimization technique. Grid search CV is used to tune hyperparameters of a machine learning model. Hyperparameters are parameters that are not learned by the model during training, but instead are set by the practitioner before training. Grid search CV performs an exhaustive search over a specified parameter grid, trying every combination of hyperparameters to find the best combination that produces the highest cross-validation accuracy score. By using grid search CV, we can avoid manually trying different combinations of hyperparameters, which can be time-consuming and error-prone."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Yes, I got significant improvement in Lasso regression model as we can see the results in below table:\n",
        "\n",
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "store_scores('Lasso regression(Grid Search CV)',4.867785094548076, 41.05151829341606, 6.407145877332282, 0.7327341804201906)\n"
      ],
      "metadata": {
        "id": "-kVNEi6XUkN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#Ridge Regression\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "ridge = Ridge()\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "ridge.fit(x_train,y_train)\n",
        "\n",
        "# Predict on the model\n",
        "\n",
        "y_pred_trridge = ridge.predict(x_train)\n",
        "y_pred_teridge = ridge.predict(x_test)\n",
        "\n",
        "# Finding the coefficients and intercept from the model-\n",
        "\n",
        "print(f'The coefficients of the model is {np.array(ridge.coef_)}')\n",
        "print(f'The intercept of the model is {ridge.intercept_}')\n"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating model performance scores for train data.\n",
        "\n",
        "calc_scores(y_train, y_pred_trridge)\n"
      ],
      "metadata": {
        "id": "XFzaeEKyap-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating model performance scores for test data.\n",
        "\n",
        "calc_scores(y_test, y_pred_teridge)\n"
      ],
      "metadata": {
        "id": "ZmE2F138ap36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualizing linearity between real and predicted data:\n",
        "\n",
        "reg_scatter(y_test, y_pred_teridge)"
      ],
      "metadata": {
        "id": "NSpk7S4ZapyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "store_scores('Ridge regression',4.873230763166252, 41.07227225075999, 6.408765267253902, 0.7325990618265394)\n"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The model used is Ridge Regression and the performance of the model was evaluated using various evaluation metrics such as mean squared error (MSE), mean absolute error (MAE), and R-squared value. These metrics were calculated on both the training and testing sets to determine the overall performance of the model. The ridge regression model achieved a mean squared error of 41.07227225075999 and a mean absolute error of 4.873230763166252 on the testing set. The R-squared value was 0.7325990618265394, indicating that the model explained 73.25% of the variance in the data."
      ],
      "metadata": {
        "id": "OyEylo9ea8zU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementation with hyperparameter optimization techniques using GridSearch CV:\n",
        "\n",
        "# Create the model\n",
        "\n",
        "model = Ridge()\n",
        "\n",
        "# Define the hyperparameters to tune\n",
        "\n",
        "params = {'alpha': [1e-15, 1e-13, 1e-10, 1e-08, 1e-05, 0.0001,\n",
        "                                   0.001, 0.01, 0.1, 1, 5, 10, 20, 30, 40, 45,\n",
        "                                   50, 55, 60, 100],}\n",
        "\n",
        "# Create the grid search object\n",
        "\n",
        "grid = GridSearchCV(model, params, cv=5)\n",
        "\n",
        "# Fit the model\n",
        "\n",
        "grid.fit(x_train, y_train)\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best hyperparameters: {}\".format(grid.best_params_))\n",
        "print(\"Best mean cross-validation score: {:.2f}\".format(grid.best_score_))"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the model using tuned hyperparameter.\n",
        "\n",
        "#Creating instance\n",
        "\n",
        "ridge = Ridge(alpha = 30)\n",
        "ridge.fit(x_train,y_train)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "ridge.fit(x_train,y_train)\n",
        "\n",
        "# Predict on the model\n",
        "y_pred_trridge = ridge.predict(x_train)\n",
        "y_pred_teridge = ridge.predict(x_test)"
      ],
      "metadata": {
        "id": "r0Q8F3nTbjVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating model performance scores for train data.\n",
        "\n",
        "calc_scores(y_train, y_pred_trridge)"
      ],
      "metadata": {
        "id": "-N3ybGIEbjGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating model performance scores for test data.\n",
        "\n",
        "calc_scores(y_test, y_pred_teridge)"
      ],
      "metadata": {
        "id": "ElH5pyy4bog5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualizing linearity between real and predicted data:\n",
        "\n",
        "reg_scatter(y_test, y_pred_teridge)"
      ],
      "metadata": {
        "id": "RM0JQe5Tbqw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Grid search CV is used to tune hyperparameters of a machine learning model. Hyperparameters are parameters that are not learned by the model during training, but instead are set by the practitioner before training. Grid search CV performs an exhaustive search over a specified parameter grid, trying every combination of hyperparameters to find the best combination that produces the highest cross-validation accuracy score. By using grid search CV, we can avoid manually trying different combinations of hyperparameters, which can be time-consuming and error-prone."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I did not find any significant difference after hyperparameter tuning:\n",
        "\n",
        "# Visualizing evaluation Metric Score chart:\n",
        "\n",
        "store_scores('Ridge regression(Grid Search CV)',4.873230763166252, 41.07227225075999, 6.408765267253902, 0.7325990618265394)\n"
      ],
      "metadata": {
        "id": "i6Kh028Ubzcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##4.ML Model 4\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#Random Forest Regression\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "65oUBV0tcre2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 4 Implementation\n",
        "rf = RandomForestRegressor()\n",
        "\n",
        "\n",
        "# Fitting the Algorithm\n",
        "\n",
        "rf.fit(x_train, y_train)\n",
        "\n",
        "\n",
        "# Predicting on the model\n",
        "\n",
        "y_train_predrf = rf.predict(x_train)\n",
        "y_test_predrf = rf.predict(x_test)\n"
      ],
      "metadata": {
        "id": "zeTCbT1Yc9sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating model performance scores for train data.\n",
        "\n",
        "calc_scores(y_train, y_train_predrf)"
      ],
      "metadata": {
        "id": "VGkntpCYc9lx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating model performance scores for test data.\n",
        "\n",
        "calc_scores(y_test, y_test_predrf)"
      ],
      "metadata": {
        "id": "5g7sSvqQc9cH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualizing linearity between real and predicted data:\n",
        "\n",
        "reg_scatter(y_test, y_test_predrf)"
      ],
      "metadata": {
        "id": "J3zv9Xf4dGl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "yeS2y9nUdQ9A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The model used is Random Forest regression and the performance of the model was evaluated using various evaluation metrics such as mean squared error (MSE), mean absolute error (MAE), and R-squared value. These metrics were calculated on both the training and testing sets to determine the overall performance of the model.\n",
        "\n",
        "* The ridge regression model achieved a mean squared error of 15.688780794063215 and a mean absolute error of 2.63099 on the testing set. The R-squared value was 0.89785822713, indicating that the model explained 89.78% of the variance in the data."
      ],
      "metadata": {
        "id": "59_biqW0dTsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "store_scores('Random Forest regression',2.6309909474063495, 15.688780794063215, 3.9609065621475112, 0.8978582271388054)\n"
      ],
      "metadata": {
        "id": "gIikQLODddOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "havZ8CEndkbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rf = RandomForestRegressor(max_depth= 30, min_samples_split = 5, n_estimators= 200)\n",
        "\n",
        "\n",
        "# Fitting the Algorithm\n",
        "\n",
        "rf.fit(x_train, y_train)\n",
        "\n",
        "\n",
        "# Predicting on the model\n",
        "\n",
        "y_train_predrf = rf.predict(x_train)\n",
        "y_test_predrf = rf.predict(x_test)"
      ],
      "metadata": {
        "id": "KD1hlalidyB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating model performance scores for train data.\n",
        "\n",
        "calc_scores(y_train, y_train_predrf)"
      ],
      "metadata": {
        "id": "uT9dHc3Rdx65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating model performance scores for test data.\n",
        "\n",
        "calc_scores(y_test, y_test_predrf)"
      ],
      "metadata": {
        "id": "EkOZT5lIdxzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualizing linearity between real and predicted data:\n",
        "\n",
        "reg_scatter(y_test, y_test_predrf)"
      ],
      "metadata": {
        "id": "4OlFrrevd2uW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "store_scores('Random Forest regression(Grid Search CV)',2.6128959118593276, 15.488846781090674, 3.9355872218883263, 0.8991598970906219)\n"
      ],
      "metadata": {
        "id": "1X_jO19Ad6mH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.ML Model - 5\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##Gradient Boosting Regression\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "9aUINzB9d9wn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "gbr = GradientBoostingRegressor()\n",
        "\n",
        "\n",
        "# Fitting the Algorithm\n",
        "\n",
        "gbr.fit(x_train, y_train)\n",
        "\n",
        "\n",
        "# Predicting on the model\n",
        "\n",
        "y_train_predgbr = gbr.predict(x_train)\n",
        "y_test_predgbr = gbr.predict(x_test)\n"
      ],
      "metadata": {
        "id": "9iQGsnG4d88z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating model performance scores for train data.\n",
        "\n",
        "calc_scores(y_train, y_train_predgbr)"
      ],
      "metadata": {
        "id": "mgds-QL8fbC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating model performance scores for test data.\n",
        "\n",
        "calc_scores(y_test, y_test_predgbr)"
      ],
      "metadata": {
        "id": "SlYhJI13fa6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualizing linearity between real and predicted data:\n",
        "\n",
        "reg_scatter(y_test, y_test_predgbr)"
      ],
      "metadata": {
        "id": "RKkCdXDkfaz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "NcR7uk1PeOMg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The model used is Gradient Boosting regression and the performance of the model was evaluated using various evaluation metrics such as mean squared error (MSE), mean absolute error (MAE), and R-squared value. These metrics were calculated on both the training and testing sets to determine the overall performance of the model.\n",
        "\n",
        "* The ridge regression model achieved a mean squared error of 25.337965384259732 and a mean absolute error of 3.7124676409203308 on the testing set. The R-squared value was 0.8350372320822267, indicating that the model explained 83.50% of the variance in the data."
      ],
      "metadata": {
        "id": "Giz0insffRjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "store_scores('Gradient Boosting regression',3.7124676409203308, 25.337965384259732, 5.033683083415138, 0.8350372320822267)\n"
      ],
      "metadata": {
        "id": "lbmYmaZ6fXpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "covzC7DLeTDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Again fitting the model after hyperparameter tuning:\n",
        "\n",
        "gbr = GradientBoostingRegressor(max_depth= 10, min_samples_split = 10, n_estimators= 100)\n",
        "\n",
        "\n",
        "# Fitting the Algorithm\n",
        "\n",
        "gbr.fit(x_train, y_train)\n",
        "\n",
        "\n",
        "# Predicting on the model\n",
        "\n",
        "y_train_predgbr = gbr.predict(x_train)\n",
        "y_test_predgbr = gbr.predict(x_test)\n"
      ],
      "metadata": {
        "id": "tk_1Djxfe_jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating model performance scores for train data.\n",
        "\n",
        "calc_scores(y_train, y_train_predgbr)"
      ],
      "metadata": {
        "id": "1DlGhanWe_b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating model performance scores for test data.\n",
        "\n",
        "calc_scores(y_test, y_test_predgbr)"
      ],
      "metadata": {
        "id": "lOkkoiiHfFhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualizing linearity between real and predicted data:\n",
        "\n",
        "reg_scatter(y_test, y_test_predgbr)"
      ],
      "metadata": {
        "id": "7HG7xvpdfFZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "store_scores('Gradient Boosting Regression(Grid Search CV)',2.5703976949659966, 15.125168528069088, 3.889108963254834, 0.9015276235572154)\n"
      ],
      "metadata": {
        "id": "JwuuYBs_fMpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "Yc1rNMXweY3v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* For the Seoul bike sharing prediction project, the evaluation metrics that would have a positive business impact are:\n",
        "\n",
        "* Root Mean Squared Error (RMSE): This metric measures the average difference between the predicted and actual values. A lower RMSE value indicates better performance of the model, which is desirable from a business perspective as it means the model is making accurate predictions and reducing errors.\n",
        "\n",
        "* Mean Absolute Error (MAE): This metric measures the absolute difference between the predicted and actual values. A lower MAE value indicates better performance of the model, which is desirable from a business perspective as it means the model is making accurate predictions and reducing errors.\n",
        "\n",
        "* R-squared (R2) score: This metric measures how well the model fits the data. A higher R2 score indicates a better fit of the model to the data, which is desirable from a business perspective as it means the model is able to explain more of the variance in the target variable.\n",
        "\n",
        "* Overall, these evaluation metrics are important for a positive business impact as they indicate how well the model is able to predict bike rental demand in Seoul, and a model that performs well on these metrics is likely to result in more accurate forecasting, improved resource allocation, and better decision making for bike-sharing companies and city planners."
      ],
      "metadata": {
        "id": "GIhQL_7AeiR8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting Model as index in r2 score dataframe:\n",
        "\n",
        "score_df = score_df.set_index('Model')"
      ],
      "metadata": {
        "id": "EIc9tjytgOJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score_df"
      ],
      "metadata": {
        "id": "gdnjPk9ogN9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualising comparison of R2 score of different models using barplot.\n",
        "\n",
        "plt.figure(figsize = (15,8))\n",
        "sns.barplot(data =score_df, x = score_df['R2 Score'], y= score_df.index, order=score_df.index, hue = score_df['R2 Score'] )\n",
        "plt.title('comparison of R2 scores of different models')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yW91qVFLgT3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Based on the provided evaluation metrics, the ML models I chose from the above created models as my final prediction model:\n",
        "* 1) **Gradient Boosting Regression(Grid Search CV)**: This model has the lowest MAE, MSE, and RMSE values, indicating that it can make more accurate predictions compared to other models. Additionally, the R2 score of 0.90 indicates that this model can explain a significant proportion of the variance in the target variable, which is desirable in bike sharing prediction. The business impact of this model can be significant as accurate predictions can help bike-sharing companies optimize their operations, improve customer satisfaction, and reduce costs.\n",
        "* 2) **Random Forest regression(Grid Search CV):** This model also has low MAE, MSE, and RMSE values, indicating good performance in prediction. The R2 score of 0.90 is also high, indicating good performance in explaining the variance in the target variable. Like the Random Forest regression model, this model can help bike-sharing companies optimize their operations, improve customer satisfaction, and reduce costs.\n",
        "* It is important to note that the business impact of these models also depends on other factors such as the cost of implementing the model, availability of data, and market conditions."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###In terms of features, Temperature ,Functioning day and Rainfall plays very important role in the above 2 models. Other features importances are different in each model."
      ],
      "metadata": {
        "id": "scXXR1__uuGP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* As we have calculated MAE,MSE,RMSE and R2 score for each model. Based on r2 score will decide our model performance.\n",
        "* Our assumption: if the differnece of R2 score between Train data and Test is more than 5 % we will consider it as overfitting.\n",
        "##Linear,Lasso and Ridge.\n",
        "\n",
        "1.    From The above data frame, we can see that linear,Lasso and Ridge regression models have almost similar R2 scores(73%) on both training and test data.(Even after using GridserachCV we have got similar results as of base models).\n",
        "\n",
        "##Random Forest:\n",
        "\n",
        "\n",
        "*   On Random Forest regressor model, without hyperparameter tuning we got r2 score as 98% on training data and 90% on test data. Thus our model memorised the data.So it was a overfitted model, as per our assumption\n",
        "* After hyperparameter tuning we got r2 score as 97% on training data and 90% on test data which is very good for us.\n",
        "\n",
        "##Gradient Boosting Regression(Gradient Boosting Machine):\n",
        "* On Random Forest regressor model, without hyperparameter tuning we got r2 score as 86% on training data and 83% on test data.Our model performed well without hyperparameter tuning.\n",
        "* After hyperparameter tuning we got r2 score as 98% on training data and 90% on test data,thus we improved the model performance by hyperparameter tuning.\n",
        "* Thus Gradient Boosting Regression(GridSearchCV) and Random forest(gridSearchCv) gives good r2 scores. We can deploy these models."
      ],
      "metadata": {
        "id": "sLduLwW8uzz_"
      }
    }
  ]
}